# Sistema de Agentes IA con Memoria

> **Â¿Buscas la documentaciÃ³n tÃ©cnica y explicaciÃ³n de la lÃ³gica? Consulta [`docs.md`](./docs.md)**

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un chat interactivo con memoria utilizando Ollama y el modelo Llama 3.2. Incluye mÃºltiples agentes personalizados con diferentes personalidades y especialidades, todos con capacidad de mantener contexto a lo largo de conversaciones completas.
## âœ¨ CaracterÃ­sticas Implementadas

### ğŸ§  Memoria de ConversaciÃ³n

- **Persistencia de contexto**: El chat mantiene historial completo de la conversaciÃ³n
- **Memoria dinÃ¡mica**: Cada sesiÃ³n mantiene su propio contexto independiente
- **GestiÃ³n inteligente**: Limita automÃ¡ticamente el historial para optimizar rendimiento

### ğŸ¤– MÃºltiples Agentes Personalizados

- **TechBot** (Soporte TÃ©cnico): Especializado en programaciÃ³n y tecnologÃ­a
- **MathBot** (Tutor de MatemÃ¡ticas): Explica conceptos matemÃ¡ticos paso a paso
- **ChefBot** (Chef Personal): Experto en cocina internacional y recetas
- **FitBot** (Entrenador Personal): Especializado en fitness y nutriciÃ³n
- **CreativeBot** (Asistente Creativo): Ayuda con proyectos artÃ­sticos y creativos
- **BizBot** (Consultor de Negocios): Orientado a estrategias empresariales

Cada agente tiene:
- **Personalidad definida**: Comportamiento y tono consistentes
- **EspecializaciÃ³n temÃ¡tica**: Conocimientos enfocados en su Ã¡rea
- **Comportamiento consistente**: Mantiene su rol a lo largo de toda la conversaciÃ³n
- **Respuestas estructuradas**: Explica conceptos de forma clara y organizada

### ğŸ–¥ï¸ Interfaz de Usuario

- **Frontend Streamlit**: Interfaz web moderna y reactiva
- **Backend Flask**: API REST robusta para gestiÃ³n de conversaciones
- **GestiÃ³n de sesiones**: MÃºltiples conversaciones independientes
- **Indicadores visuales**: Estados de conexiÃ³n y contadores de mensajes
- **CreaciÃ³n de agentes personalizados**: Interfaz para definir nuevos agentes

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP/JSON    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Python SDK    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚                 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚                 â”‚
â”‚   Streamlit     â”‚                 â”‚   Flask API     â”‚                  â”‚     Ollama      â”‚
â”‚   (Frontend)    â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚   (Backend)     â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚   (Llama 3.2)   â”‚
â”‚                 â”‚    Responses    â”‚                 â”‚    Responses     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos:

1. Usuario envÃ­a mensaje en Streamlit
2. Streamlit hace POST a Flask API
3. Flask recupera historial de conversaciÃ³n (memoria)
4. Flask envÃ­a contexto completo a Ollama
5. Ollama procesa con Llama 3.2 y responde
6. Flask guarda respuesta en memoria y la retorna
7. Streamlit muestra respuesta al usuario

## ğŸ“ Estructura del Proyecto

```
agent_with_memory/
â”œâ”€â”€ app.py                 # Servidor Flask con memoria y agentes
â”œâ”€â”€ web.py                 # Interfaz Streamlit
â”œâ”€â”€ test_memory.py         # Script de pruebas automatizadas
â”œâ”€â”€ requirements.txt       # Dependencias Python
â””â”€â”€ README.md              # DocumentaciÃ³n
```
## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### Prerequisitos

- Ollama instalado: Descargar de [ollama.com](https://ollama.com)
- Modelo Llama 3.2: `ollama pull llama3.2:1b`
- Python 3.8+

### Pasos de instalaciÃ³n:

```bash
# 1. Clonar o descargar los archivos del proyecto
cd tu-directorio-proyecto

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Verificar que Ollama estÃ© corriendo
ollama list  # Debe mostrar llama3.2:1b
```

### OpciÃ³n 1: Inicio RÃ¡pido (Recomendado)

```bash
# Desde la carpeta raÃ­z del proyecto
./start.sh agent_with_memory
```

> **Nota:** El comando `npm run start-agent` solo funciona si tienes el script definido en el `package.json` de la raÃ­z del monorepo. Si no usas Node.js, ejecuta el script bash directamente como arriba.

### OpciÃ³n 2: Inicio Manual

```bash
# Terminal 1 - Ejecutar servidor Flask
python app.py
# o
flask run --port=5050
 
# Terminal 2 - Ejecutar Streamlit
streamlit run web.py

# Terminal 3 (Opcional) - Ejecutar pruebas automatizadas
python test_memory.py
```

### URLs de acceso:

- **Chat Interface**: http://localhost:8501
- **Flask API**: http://127.0.0.1:5050

### API Endpoints:

- **GET /agents** - Listar agentes disponibles
- **POST /set_agent** - Cambiar agente
- **POST /create_custom_agent** - Crear agente personalizado
- **POST /chat** - Enviar mensaje
- **POST /reset** - Reiniciar conversaciÃ³n



ğŸ§ª Pruebas de Funcionalidad
Pruebas Manuales

Memoria: Haz preguntas de seguimiento que dependan de respuestas anteriores
Agente: Observa la personalidad consistente de TechBot
Contexto: Verifica que recuerda informaciÃ³n de mensajes previos

Pruebas Automatizadas
Ejecuta python test_memory.py para probar:

âœ… Persistencia de memoria
âœ… Personalidad del agente
âœ… Contexto de conversaciÃ³n
âœ… Conectividad con Ollama

## ğŸ’¬ Ejemplos de Uso por Agente

### TechBot (Soporte TÃ©cnico)
- "Â¿CÃ³mo instalo Python en Windows?"
- "ExplÃ­came quÃ© son las APIs REST"
- "Tengo un error en mi cÃ³digo JavaScript: Uncaught TypeError"

### MathBot (Tutor de MatemÃ¡ticas)
- "Â¿CÃ³mo resuelvo ecuaciones cuadrÃ¡ticas?"
- "ExplÃ­came el teorema de PitÃ¡goras con ejemplos"
- "Necesito ayuda con cÃ¡lculo diferencial"

### ChefBot (Chef Personal)
- "Receta para pasta sin gluten"
- "Â¿CÃ³mo preparar un risotto perfecto?"
- "Ideas para cena romÃ¡ntica vegetariana"

### FitBot (Entrenador Personal)
- "Rutina para principiantes en casa"
- "Ejercicios para mejorar resistencia"
- "Plan de alimentaciÃ³n para ganar mÃºsculo"

### CreativeBot (Asistente Creativo)
- "Ideas para un proyecto de fotografÃ­a"
- "Â¿CÃ³mo superar el bloqueo creativo?"
- "TÃ©cnicas de pintura para principiantes"

### BizBot (Consultor de Negocios)
- "Â¿CÃ³mo crear un plan de negocios?"
- "Estrategias de marketing digital"
- "Consejos para una startup tecnolÃ³gica"

### Ejemplo de ConversaciÃ³n con Memoria:

Usuario: "Hola, necesito ayuda con Python"

TechBot: "Â¡Hola! Soy TechBot... Â¿QuÃ© aspecto especÃ­fico de Python te gustarÃ­a aprender?"

Usuario: "Â¿QuÃ© son las listas?"

TechBot: "Las listas en Python son estructuras de datos... [explicaciÃ³n detallada]"

Usuario: "Â¿Puedes darme un ejemplo de lo que acabas de explicar?"

TechBot: "Â¡Por supuesto! BasÃ¡ndome en la explicaciÃ³n sobre listas que te di..."
                    â†‘ (Demuestra memoria del contexto anterior)
## ğŸ”§ ConfiguraciÃ³n de Agentes

### Agentes Predefinidos

El sistema incluye varios agentes predefinidos con diferentes personalidades:

| Agente | Rol | EspecializaciÃ³n | Tono | Estilo |
|--------|-----|----------------|------|--------|
| TechBot | Asistente de Soporte TÃ©cnico | ProgramaciÃ³n y tecnologÃ­a | Amigable, profesional | Explicaciones paso a paso con ejemplos |
| MathBot | Tutor de MatemÃ¡ticas | Conceptos matemÃ¡ticos | Paciente, motivador | AnalogÃ­as y verificaciÃ³n de comprensiÃ³n |
| ChefBot | Chef Personal | Cocina internacional | Apasionado, creativo | Recetas adaptables con tips profesionales |
| FitBot | Entrenador Personal | Fitness y nutriciÃ³n | Motivador, enÃ©rgico | Rutinas personalizadas con tÃ©cnicas correctas |
| CreativeBot | Asistente Creativo | Proyectos artÃ­sticos | Inspirador, no crÃ­tico | Sugerencias especÃ­ficas para superar bloqueos |
| BizBot | Consultor de Negocios | Estrategias empresariales | Profesional, orientado a resultados | AnÃ¡lisis de viabilidad y estrategias accionables |

### PersonalizaciÃ³n de Agentes

Hay dos formas de personalizar los agentes:

#### 1. Desde la Interfaz Web

Utiliza la secciÃ³n "Crear Agente Personalizado" en el sidebar de la interfaz web para definir:
- Nombre del agente
- Instrucciones y personalidad detalladas

#### 2. Modificando el CÃ³digo

Para aÃ±adir nuevos agentes predefinidos, modifica el diccionario `AVAILABLE_AGENTS` en `app.py`:

```python
AVAILABLE_AGENTS = {
    "nuevo_agente": {
        "name": "Nombre del Agente",
        "description": "DescripciÃ³n corta",
        "system_message": '''Instrucciones detalladas sobre la personalidad, 
        comportamiento y especializaciÃ³n del agente...'''
    },
    # ... otros agentes existentes
}
## ğŸ¯ Cumplimiento de Requisitos

| Requisito | Estado | Detalles |
|-----------|--------|----------|
| **Chat interactivo con Ollama y Llama 3.2** | âœ… | â€¢ Implementado con Flask + Streamlit<br>â€¢ Usa modelo llama3.2:1b |
| **Memoria para mantener contexto** | âœ… | â€¢ Sistema de historial persistente<br>â€¢ Contexto completo en cada llamada<br>â€¢ GestiÃ³n inteligente de memoria |
| **MÃºltiples agentes personalizados** | âœ… | â€¢ 6 agentes predefinidos con personalidades distintas<br>â€¢ Comportamiento consistente<br>â€¢ EspecializaciÃ³n por Ã¡reas temÃ¡ticas |
| **InvestigaciÃ³n de documentaciÃ³n** | âœ… | â€¢ ImplementaciÃ³n basada en mejores prÃ¡cticas de Ollama<br>â€¢ Uso correcto de mensajes con roles (system, user, assistant) |
| **Scripts Python funcionales** | âœ… | â€¢ Backend Flask robusto<br>â€¢ Frontend Streamlit interactivo<br>â€¢ Script de pruebas automatizadas |

## ğŸ“Š MÃ©tricas de Rendimiento

| MÃ©trica | Valor | Notas |
|---------|-------|-------|
| **Tiempo de respuesta** | ~2-5 segundos | Depende del hardware |
| **GestiÃ³n de memoria** | 20 mensajes + sistema | Optimizado para balance entre contexto y rendimiento |
| **Sesiones concurrentes** | MÃºltiples | Cada usuario mantiene sesiÃ³n independiente |
| **TamaÃ±o de contexto** | Optimizado | Evita lÃ­mites de tokens del modelo |

## ğŸ” SoluciÃ³n de Problemas

| Problema | SoluciÃ³n |
|----------|----------|
| **"model not found"** | ```bash
ollama pull llama3.2:1b
``` |
| **"Connection refused"** | â€¢ Verificar que Ollama estÃ© corriendo<br>â€¢ Verificar que Flask estÃ© en puerto 5050 |
| **Respuestas lentas** | â€¢ Normal con modelos locales<br>â€¢ Considera usar modelo mÃ¡s pequeÃ±o |

## ğŸ“ Conceptos TÃ©cnicos Implementados

### Memoria de ConversaciÃ³n
- **Persistencia**: Almacenamiento en memoria del servidor
- **Contexto completo**: Cada llamada incluye historial completo
- **GestiÃ³n de tokens**: Limita historial para evitar overflow

### Agentes con Personalidad
- **System Message**: Define comportamiento del agente
- **Consistencia**: Mantiene personalidad a lo largo de conversaciÃ³n
- **EspecializaciÃ³n**: Enfoque especÃ­fico por Ã¡rea temÃ¡tica

### Arquitectura
- **SeparaciÃ³n de responsabilidades**: Frontend/Backend separados
- **API RESTful**: Endpoints bien definidos
- **GestiÃ³n de estado**: Sesiones independientes por usuario

## ğŸ† ConclusiÃ³n

Este proyecto demuestra una implementaciÃ³n completa de un sistema de chat inteligente con:

- âœ… **Memoria funcional** que mantiene contexto a lo largo de conversaciones
- âœ… **MÃºltiples agentes personalizados** con comportamientos consistentes
- âœ… **Interfaz profesional** fÃ¡cil de usar con opciones de personalizaciÃ³n
- âœ… **Arquitectura escalable** y bien estructurada para futuras expansiones
- âœ… **Pruebas automatizadas** para validar la funcionalidad

Todas las especificaciones del proyecto han sido implementadas exitosamente, creando un sistema versÃ¡til que puede adaptarse a diferentes necesidades de conversaciÃ³n.